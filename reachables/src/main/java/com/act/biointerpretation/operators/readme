*  This package is a sidebar project alongside the cofactors package to ultimately
   be used in the mechanisminspection phase of database cleaning

*  The goal of the package is to construct a first-pass set of reaction operators,
   curate them, and make them available as an oracle to the MechanisticCleaner

*  This code is a daisy chain of running analyses over the database, generating data, curating,
    then feeding that back into the next step.  So, it's complicated.  I will try to describe the
    sequence of events.

***********************
Core Algorithmic Pieces:
***********************

SkeletonMapper and ChangeMapper
*   These are for generating Atom-To-Atom mappings of a reaction.  ChangeMapper just does the
    appropriate ChemAxon AutoMapper
*   SkeletonMapper first maps the carbon backbone, then the
    first shell of heteroatoms, then the rest of the molecule.

SubstructureMatcher
*   This is used by SkeletonMapper

OperatorExtractor
*   Calculates the various types of h*ERO and h*CRO's for a mapped reaction
*   The explanation of the different RO types is at:  https://github.com/20n/act/issues/107
*   ROExtractor_old is vestigial code
*   ROProjector I think is functioning code not used in this project, and will likely be moved


ReactionInterpretation
*   A representation of a reaction with it's cofactors pulled out, it's mapping, and its ROs
*   During CrawlAndHmERO, these all get dumped to disk
*   Files are human-readable, and parsed and exported with toString and parse methods

ChemAxonUtils.getReactionHash(RxnMolecule cro)
*   Calculates a hash code for a reaction
*   Converts everything to single substrate and product Molecule
*   Dumps it as a String of inchi >> inchi
*   Works on concrete and abstract reactions
*   When saved to disk, I create a SHA1 hash of this to avoid illegal characters

***********************
Analysis:
***********************

Notes
* This is my best attempt at reconstituting the flow of the analysis
* I don't recall the distinction between the three CompareRO classes and where each was used (if used)

1. CrawlAndAbstract
*  This crawls through the database and hashes up all the hcEROs observed
*  It was run on synapse, which is the db that's gone through ReactionMerging and Desalting

2. CompareROs
*  Separates the ERO information into separate MetaCyc and BRENDA collections
*  It compares the two collection and only retains those hcEROs present at least twice in each source db

3. CrawlMapAndSave
*  Goes back through all the reactions that survive CompareROs and calculates mappings and persists them on disk
*  It does it with both SkeletonMapper and ChangeMapper
*  It dumps a bunch of files on the hardrive that are serialized objects as files

4.  CrawlAndHmERO
*  Scans through all the mapping files from previous and creates a directory of files called output/hmERO
*  this output directory is organized by CRO>hmERO>hcERO>reactions
*  Currently I have only processed the SkeletonMapper-derived mappings, because ChangeMap generates too much crap
*  This will result in loss of carbon-carbon altering reactions, but can curate them back later

5. OperatorGUIHelper and OperatorGUI
*  To run, run OperatorGUIHelper which will initialize the GUI
*  OperatorGUI is the GUI, the Helper is a controller
*  Helper examines the data generated by CrawlAndHmERO and prioritizes things for curation
*  Curation involves generating JSON files using another GUI (launched from OperatorGUI) called utils/JSONFileEditor
*  The JSON files are dumped in the terminal CRO>hmERO>hcERO>reactions path
*  I curated the top 450 reactions, which took me down to the middle of ROs with only 2 examples
*  I was still seeing good data after 450.
*  The SkeletonMapper is a strong constraint for a good reaction. Very few are wrong.

6. ConsolidateCuration
*  Goes through the hmERO directory and pulls out all the JSON, the hcERO, and the directory location
*  It enumerates all the keys observed in the JSON (it println's them)
*  Those keys mean things to me, and their values will be used in next steps, but they are all generated by curation
*  A copy of the hmERO data including all the curated JSON is on the Dropbox at:
    Dropbox\ \(20n\)/20n\ Team\ Folder/act_data/2015_12_21-hmEROs.zip

*  The key list was:

confidence
validation
name
note
cyclase
hydrate
trim
cofactor
aam
nro
twotimes
twosites
error
NRO
mixed_products
twostep
glucosyltransferase
desalting
tirm
tautomer
stereo
coenzyme

* repeated, with explanation:

confidence  -  high, med, low; my confidence in the validation of the bag of reaction data
validation  -  true/false; if the reactions that abstract to this hcERO are valid
name    -  String; provides a name for ERO for the more common things
note    -  Additional info to facilitate cleaning up the EROs that are imperfect
cyclase -  Whether it is an isoprenoid cyclase
hydrate -  Whether a chemical participating in the reaction contains a hydrate, a grey area due to instability
trim    -  Whether the reaction can be pruned by a more abstract one, benchmarking data for curation effort
cofactor    -  Whether the reaction describes a cofactor that was not abstracted
aam     -  There is an error in the atom-to-atom mapping
nro     -  Whether the hcERO is too abstract and instead needs an NRO, usually means a ring is necessary
twotimes    - Common reaction applied twice to the molecule
twosites    - Common reaction applied twice to the molecule
error   -  There is an error in the raw data
NRO  -  Whether the hcERO is too abstract and instead needs an NRO, usually means a ring is necessary
mixed_products  -  There are two reaction products
twostep     - Common reaction applied twice to the molecule
glucosyltransferase   - encodes a glycosyltransferase, not commonly used
desalting    -  A desalting error is present
tirm        -  same as trim
tautomer    -  A molecule in the reaction is an uncommon tautomer
stereo      -  ehh, not sure what that means
coenzyme    -  There is a coenzyme that is not abstracted.  I think this only occurs once. And currently unhandled.

7.  Cofactor Curation
*  The previous also generates a file of potential cofactors (inspection of cofactor key in json) called:
        output/potentialCofactors.txt
*  I curated all the chems in that file and put in good names for each real cofactor
*  A copy of the curated output is at: Dropbox\ \(20n\)/20n\ Team\ Folder/act_data/potentialCofactors.txt
*  I combined the new cofactors from this curation with the old ones (Dropbox\ \(20n\)/20n\ Team\ Folder/act_data/cofactor_data.txt)
*  The combined file is:
        Dropbox\ \(20n\)/20n\ Team\ Folder/act_data/2015_12_21-Cofactors.txt
*  I added a column in that file where I prioritize each cofactor as 1, 2, or 3
    1:  This is almost always a cofactor and does little else (ie, ATP)
    2:  This is a well=recognized cofactor, but it also shows up in reactions that are about something else (nucleotide sugars)
    3:  These are only sometimes cofactors (glutamine)
*  It is not a strict thing, just a heuristic for correctly pulling out cofactors in the MechanisticValidator
*  I will copy this file into the /data/ folder to pull from it in the codebase

8.  ConsolidatedCurationPart2 -- Test-Set Generation
*   Pulls reaction list for all validated reactions (plus a few other constraints)
*   Generated by generateTestSet() method
*   Results in a list of 5553 files to be used for validation

9.  ConsolidatedCurationPart2 -- Perfect RO extraction
*   Extract the ROs that have no problems in the curation
*   Another method generatePerfectROs()
*   Validation must be true
*   AAM must be null
*   nro must be null
*   cofactor must be null
*   There are at least three tags in the json
*   Various other constraints on the curation tags
*   This results in 247 ROs

10.  TestSetCrossROs
*  Runs ConsolidatedCurationPart2 and pulls the perfect ROs and testset
*  Goes through each reaction in the test set and projects all ROs over it
*  If an RO predicts the product(s) of a test reaction, that rxnid is added to the RORecord
*  Results are serialized to file for next step

11.  ROPruner
*  Deserializes the result from (10) and does trimming
*  If all the reactions that pass one RO are a subset of those from another, then the it should be eliminated (trimmed out)
*  Operationally, to trim something means to set the RORecord.trimResult to true
*  Serializes the modified TestSetCrossRos object with the new Trim values as another .ser file
*  Also outputs a list of ROs --  LOST THE NAMES!!!!

11.  MechanisticValidator
(not written yet)

12.  Run over metacyc
(not written yet)


